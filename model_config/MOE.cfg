[Model]
;512 for ml-1m, 256 for yelp, 256 for amazon_cd
batch_size=512
test_batch_size=1024

num_local_threads=5

lr=0.001
;changed batch size, change lr
;lr=0.0005
;dropout=0.2
dropout=0
;ml-1m
reg=1e-3
;other datasets
;reg = 1e-4

# ======= MultVAE
;enc_dims=[200]
enc_dims=[100]
anneal_cap=0.2
total_anneal_steps=200000

# ======= MOE, config
num_experts: 100
expert: 'MultVAE'